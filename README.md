# LLM Finetuning using LoRA on Custom Dataset

This repository demonstrates how to fineâ€‘tune large language models (LLMs) using **LoRA (Lowâ€‘Rank Adaptation)** on a custom dataset. LoRA is a parameterâ€‘efficient technique that allows you to adapt powerful pretrained models (like Mistral, LLaMA, or GPTâ€‘style architectures) without retraining the entire network. This makes fineâ€‘tuning faster, cheaper, and more accessible.

---

## ğŸš€ Features
- Fineâ€‘tune stateâ€‘ofâ€‘theâ€‘art LLMs with LoRA adapters
- Train on your own custom dataset (e.g., Q&A pairs, domainâ€‘specific text)
- Save and load adapters separately from the base model

---

## ğŸ“‚ Project Structure
- `main.py` â€“ entry point for training and evaluation
- `src/` â€“ helper scripts (data preprocessing, finetuning, prompt generation)
- `data/` â€“ place your custom dataset files (e.g., `QA.json`)
- `workspace/` â€“ model checkpoints and outputs (ignored in `.gitignore`)
- `.gitignore` â€“ ensures large files (weights, cache, PDFs) are not pushed to GitHub


### ğŸ“ PDFtoQA.py
- Converts a PDF into text and splits it into smaller chunks  
- Builds a prompt that instructs an LLM to generate Q&A pairs from each chunk  
- Streams responses back from the LLM in real time  
- Cleans and parses the responses into valid JSON with `"question"` and `"answer"` fields  
- Collects all Q&A pairs and saves them into a JSON file for later use  


### ğŸ§  finetuning.py
- **Dataset preparation**  
  - Loads a dataset containing `question` and `answer` fields  
  - Formats each entry into a chatâ€‘style template (system, user, assistant roles)  
  - Produces text samples suitable for instructionâ€‘tuning  

- **Tokenizer setup**  
  - Loads the tokenizer for the chosen base model  
  - Applies the custom chat template to dataset entries  

- **Model setup with quantization**  
  - Loads the base language model with 4â€‘bit quantization (`BitsAndBytesConfig`) to save memory  
  - Enables gradient checkpointing for efficiency  
  - Prepares the model for lowâ€‘bit training  

- **LoRA configuration**  
  - Defines LoRA adapter parameters (rank, alpha, dropout, target modules, task type)  
  - Wraps the model with LoRA for parameterâ€‘efficient fineâ€‘tuning  

- **Trainer setup and training**  
  - Uses `SFTTrainer` (Supervised Fineâ€‘Tuning) from TRL to train the model  
  - Configures training (epochs, logging, disables checkpoint saving)  
  - Runs the training loop on the prepared dataset  

- **Model saving and publishing**  
  - Saves the trained model locally (`complete_checkpoint`, `final_model`)  
  - Optionally pushes the model and tokenizer to Hugging Face Hub if a `repo_id` is 



---

## âš™ï¸ Requirements
Install dependencies:
pip install -r requirements.txt




# Run training

python main.py



## âœ¨ Author

Developed by Antonio Maria Fiscarelli This repository is a personal project exploring efficient fineâ€‘tuning of LLMs.